{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bba44cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd446e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tj/9f4bs_0n69b_w28_xyk24sfh0000gn/T/ipykernel_4323/1949518271.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver= webdriver.Chrome('//Users/raj/Desktop/chromedriver')\n"
     ]
    }
   ],
   "source": [
    "driver= webdriver.Chrome('//Users/raj/Desktop/chromedriver')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381c12aa",
   "metadata": {},
   "source": [
    "# Q1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfd10671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening webpage\n",
    "url='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11aa830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty list for scraping data\n",
    "Rank =[]\n",
    "Name =[]\n",
    "Artist =[]\n",
    "Upload_date=[]\n",
    "Views=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce56a79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank Via X path\n",
    "try:\n",
    "    rank=driver.find_elements(\"xpath\",'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Rank.append('NA')\n",
    "    \n",
    "# Extracting Name Via X path\n",
    "try:\n",
    "    name=driver.find_elements(\"xpath\",'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Name.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Name.append('NA')\n",
    "    \n",
    "# Extracting Artist Name Via Xpath\n",
    "try:\n",
    "    artist=driver.find_elements(\"xpath\",\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\")\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Artist.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Artist.append('NA')\n",
    "    # Extracting Upload date Via Xpath\n",
    "try:\n",
    "    upload_date=driver.find_elements(\"xpath\",\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\")\n",
    "    for i in upload_date:\n",
    "        Upload_date.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Upload_date.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Upload_date.append('NA') \n",
    "\n",
    "# Extracting Views via Xpath\n",
    "try:\n",
    "    views=driver.find_elements(\"xpath\",\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\")\n",
    "    for i in views:\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementExceptionhElementException:\n",
    "    Views.append('NA')\n",
    "except StaleElementReferenceException:\n",
    "    Views.append('NA')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26841fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for scrap data\n",
    "Wiki_YT=pd.DataFrame({'Rank':Rank,'Video Name':Name,'Uploader':Artist,'Views (in Billons)':Views,'Upload Date':Upload_date})\n",
    "print('\\033[1m'+'Most Viewed Video on YouTube from Wikipedia :'+'\\033[0m')\n",
    "Wiki_YT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7958a920",
   "metadata": {},
   "source": [
    "# Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25eb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome('//Users/raj/Desktop/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e315b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening webpage\n",
    "url='https://www.bcci.tv/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5bd2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening fixtures webpage through browser\n",
    "fixtures=driver.find_element(\"xpath\",\"/html/body/nav/div[1]/div[2]/ul[1]/li[2]\")\n",
    "try:\n",
    "    fixtures.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(fixtures.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07194200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping URL \n",
    "URL= []\n",
    "link=driver.find_elements(\"xpath\",'/html/body/div[2]/div[2]/div/div/div/div[2]/div[3]/div[1]/div[2]/div/div[4]/a')\n",
    "for i in link:\n",
    "    URL.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf474148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Title = []\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00843912",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(URL):\n",
    "    driver.get(i)\n",
    "    \n",
    "    # Scraping Match title\n",
    "    try:\n",
    "        title=driver.find_element(\"xpath\",\"//p[@class='mc-header-info__match-description']/span\")\n",
    "        Title.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        Title.append('NA')\n",
    "        \n",
    "    # Scraping Series Via Xpath\n",
    "    try:\n",
    "        series=driver.find_element(\"xpath\",\"//h1[@class='mc-header-info__title']/strong\")\n",
    "        Series.append(series.text)\n",
    "    except NoSuchElementException:\n",
    "        Series.append('NA')\n",
    "        \n",
    "    # Scraping venue Via Xpath\n",
    "    try:\n",
    "        place=driver.find_element(\"xpath\",\"//h1[@class='mc-header-info__title']\")\n",
    "        Place.append(place.text)\n",
    "    except NoSuchElementException:\n",
    "        Place.append('NA')\n",
    "        \n",
    "    # Scraping date Via Xpath\n",
    "    try:\n",
    "        date=driver.find_element(\"xpath\",'//div[@class=\"mc-header-scorebox__datetime\"]/strong')\n",
    "        Date.append(date.text)\n",
    "    except NoSuchElementException:\n",
    "        Date.append('NA')\n",
    "        # Scraping Time Via Xpath\n",
    "    try:\n",
    "        time=driver.find_element(\"xpath\",'//div[@class=\"mc-header-scorebox__datetime\"]/span')\n",
    "        Time.append(time.text)\n",
    "    except NoSuchElementException:\n",
    "        Time.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d7badc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for scrap data\n",
    "Cricket=pd.DataFrame({'Match Title':Title,'Tournament':Series,'Venue':Place,'Date':Date,'Time':Time})\n",
    "print('\\033[1m'+'Team Indiaâ€™s Upcoming International fixtures :'+'\\033[0m')\n",
    "Cricket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3827f1",
   "metadata": {},
   "source": [
    "# Q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086aa17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome('//Users/raj/Desktop/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d3c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening webpage\n",
    "url='https://www.guru99.com/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99bf5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty list\n",
    "Name =[]\n",
    "Description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e731a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Selenium option from website\n",
    "Selenium=driver.find_element(\"xpath\",'//div[@class=\"featured-box cloumnsize1\"]/ul[1]/li[3]/a')\n",
    "try:\n",
    "    Selenium.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(Selenium.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00eb6af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Selenium Exception handling option from website\n",
    "Selenium_Exception=driver.find_element(\"xpath\",'//*[@id=\"post-193\"]/div/div/table[5]/tbody/tr[34]/td[1]/a')\n",
    "try:\n",
    "    Selenium_Exception.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(Selenium_Exception.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Exception Name via Xpath\n",
    "try:\n",
    "    name=driver.find_elements(\"xpath\",'//html/body/div[1]/div/div/div/main/div/article/div/header/div/span[1]/span[2]/a')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('NA')\n",
    "    \n",
    "# Extracting Description via Xpath\n",
    "try:\n",
    "    description=driver.find_elements(\"xpath\",'/html/body/div[1]/div/div/div/main/div/article/div/div/div[2]/p[1]')\n",
    "    for i in description:\n",
    "        Description.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Description.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d35ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Name),len(Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d651b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for scrap data\n",
    "Exception=pd.DataFrame({'Exception Type':Name,'Description':Description})\n",
    "print('\\033[1m'+'Selenium Exception from Guru 99 :'+'\\033[0m')\n",
    "Exception"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a47c6",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome('//Users/raj/Desktop/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening webpage\n",
    "url='https://www.statisticstimes.com/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca13c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty lists\n",
    "Rank =[]\n",
    "State =[]\n",
    "GDSP_19_20=[]\n",
    "GDSP_18_19 =[]\n",
    "Share =[]\n",
    "GDP =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f760343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on India under ecomony section\n",
    "India=driver.find_element(\"xpath\",'/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "try:\n",
    "    India.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(India.get_attribute('href'))\n",
    "    \n",
    "time.sleep(2)\n",
    "\n",
    "# Clicking Indian State GDP\n",
    "state = driver.find_element(\"xpath\",'//ul[@style=\"list-style-type:none;margin-left:20px;\"]/li[1]/a')\n",
    "try:\n",
    "    state.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(state.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a9cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Rank via Xpath\n",
    "try:\n",
    "    rank=driver.find_elements(\"xpath\",'//table[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "    for i in rank:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('NA')\n",
    "    \n",
    "# Extracting state name via Xpath\n",
    "try:\n",
    "    state=driver.find_elements(\"xpath\",'//table[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "    for i in state:\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append('NA')\n",
    "    \n",
    "# Extracting GDSP 19-20 via Xpath\n",
    "try:\n",
    "    gdsp_19_20=driver.find_elements(\"xpath\",'//table[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "    for i in gdsp_19_20:\n",
    "        GDSP_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDSP_19_20.append('NA')\n",
    "    \n",
    "# Extracting GDSP 18-19 via Xpath\n",
    "try:\n",
    "    gdsp_18_19=driver.find_elements(\"xpath\",'//table[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "    for i in gdsp_18_19:\n",
    "        GDSP_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDSP_18_19.append('NA')\n",
    "    \n",
    "# Extracting share in billons via Xpath\n",
    "try:\n",
    "    share=driver.find_elements(\"xpath\",'//table[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "    for i in share:\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append('NA')\n",
    "# Extracting GDP via Xpath\n",
    "try:\n",
    "    gdp=driver.find_elements(\"xpath\",'//table[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "    for i in gdp:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf66e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe for scrap data\n",
    "Statewise_GDP=pd.DataFrame({'Rank':Rank,'State':State,'GDSP 19-20':GDSP_19_20,'GDSP 18-19':GDSP_18_19,\n",
    "                            'Share':Share,'GDP (in Billions)':GDP})\n",
    "print('\\033[1m'+'State-wise GDP of India :'+'\\033[0m')\n",
    "Statewise_GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedc17e6",
   "metadata": {},
   "source": [
    "# Q5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c59413",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome('//Users/raj/Desktop/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb73fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening webpage\n",
    "url='https://github.com/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbba7951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on trending option\n",
    "trending=driver.find_element(\"xpath\",'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]')\n",
    "try:\n",
    "    trending.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty list for Scraping Data\n",
    "Title=[]\n",
    "Description=[]\n",
    "Count =[]\n",
    "Language =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e0fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping repositories URL\n",
    "URL= []\n",
    "link=driver.find_elements(\"xpath\",'/html/body/div[1]/div[4]/main/div[3]/div/div[2]/article[1]/h1/a')\n",
    "for i in link:\n",
    "    URL.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab509cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e47178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Repositority Title\n",
    "try:\n",
    "    title=driver.find_elements(\"xpath\",'//h1[@class=\"h3 lh-condensed\"]')\n",
    "    for i in title:\n",
    "        Title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Title.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282d4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c705870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(URL):\n",
    "    driver.get(i)\n",
    "    time.sleep(5)\n",
    "    # Scraping Description\n",
    "    try:\n",
    "        description=driver.find_element(\"xpath\",'/html/body/div[4]/div/main/div[2]/div/div/div[2]/div[2]/div/div[1]/div/p')\n",
    "        Description.append(description.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('NA')\n",
    "    \n",
    "    # Scraping Contributor count\n",
    "    try:\n",
    "        count=driver.find_element(\"xpath\",\"//h2[@class='h4 mb-3']/a[contains(text(),'Contributors')]/span\")\n",
    "        Count.append(count.text)\n",
    "    except NoSuchElementException:\n",
    "        Count.append('NA')\n",
    "    \n",
    "    # Scraping Language\n",
    "    L =[]\n",
    "    try:\n",
    "        lang=driver.find_elements(\"xpath\",\"//li[@class='d-inline']//a//span[1]\")\n",
    "        if lang:\n",
    "            for j in lang:\n",
    "                L.append(j.text)\n",
    "        else:\n",
    "            L.append('NA')\n",
    "        Language.append(L)\n",
    "    except NoSuchElementException:\n",
    "        Language.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bc2741",
   "metadata": {},
   "outputs": [],
   "source": [
    "Github=pd.DataFrame({'Title':Title,'Description':Description,\n",
    "                'Contributors_count':Count,'Language_used':Language})\n",
    "print('\\033[1m'+'GitHub Trending Repository :'+'\\033[0m')\n",
    "Github"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abacf79",
   "metadata": {},
   "source": [
    "# Q6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86c6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome('//Users/raj/Desktop/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b33356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening webpage\n",
    "url='https://www.billboard.com/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea121c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List\n",
    "Song =[]\n",
    "Artist =[]\n",
    "Last_Week_rank=[]\n",
    "Peak_rank =[]\n",
    "Weeks =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0addbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on hot 100 option\n",
    "hot_100=driver.find_element(\"xpath\",'/html/body/div[4]/div[9]/div/div/div/ul/li[1]/ul/li[2]/a')\n",
    "try:\n",
    "    hot_100.click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(hot_100.get_attribute('href'))\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b0b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Song Name\n",
    "try:\n",
    "    song=driver.find_elements(\"xpath\",'//span[@class=\"chart-element__information\"]/span[1]')\n",
    "    for i in song:\n",
    "        Song.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Song.append('NA')\n",
    "    \n",
    "# Scraping Song Artist Name\n",
    "try:\n",
    "    artist=driver.find_elements(\"xpath\",'//span[@class=\"chart-element__information\"]/span[2]')\n",
    "    for i in artist:\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append('NA')\n",
    "    \n",
    "# Scraping Song last week rank\n",
    "try:\n",
    "    last_rank=driver.find_elements(\"xpath\",'//span[@class=\"chart-element__information\"]/span[2]')\n",
    "    for i in last_rank:\n",
    "        Last_Week_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Last_Week_rank.append('NA')\n",
    "\n",
    "# Scraping Song peak rank\n",
    "try:\n",
    "    peak=driver.find_elements(\"xpath\",'//span[@class=\"chart-element__information\"]/span[2]')\n",
    "    for i in peak:\n",
    "        Peak_rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Peak_rank.append('NA')\n",
    "\n",
    "# Scraping Song Artist Name\n",
    "try:\n",
    "    weeks=driver.find_elements(\"xpath\",'//span[@class=\"chart-element__information\"]/span[2]')\n",
    "    for i in weeks:\n",
    "        Weeks.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Weeks.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5deee",
   "metadata": {},
   "outputs": [],
   "source": [
    "Billboard=pd.DataFrame({'Song_Name':Song,\n",
    "                'Artist_Name':Artist,\n",
    "                'Last_week_rank':Last_Week_rank,\n",
    "                'Peak':Peak_rank,\n",
    "                'Weeks_on_chart':Weeks})\n",
    "print('\\033[1m'+'Billboard Hot 100 Songs :'+'\\033[0m')\n",
    "Billboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a167106d",
   "metadata": {},
   "source": [
    "# Q7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0f117",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome('//Users/raj/Desktop/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d3bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening webpage\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec89c48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on recuriters option\n",
    "recruiters=driver.find_element(\"xpath\",\"//a[@title='Search Recruiters']\")\n",
    "driver.get(recruiters.get_attribute('href'))\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locating Search bar via Xpath\n",
    "Search=driver.find_element(\"xpath\",\"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div/input\")\n",
    "\n",
    "# Sending data science as key in search bar\n",
    "Search.send_keys(\"Data Science\")\n",
    "time.sleep(1)\n",
    "\n",
    "#clicking on search button\n",
    "button=driver.find_element(\"xpath\",\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "button.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List\n",
    "Name =[]\n",
    "Designation =[]\n",
    "Company =[]\n",
    "Skill =[]\n",
    "Location =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ff34c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping  Name\n",
    "try:\n",
    "    name=driver.find_elements(\"xpath\",'//a[@class=\"ellipsis\"]/span')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "        Name.append('NA')\n",
    "\n",
    "    # Scraping Designation\n",
    "try:\n",
    "    designation=driver.find_elements(\"xpath\",'//p[@class=\"highlightable\"]/span[1]')\n",
    "    for i in designation:\n",
    "        Designation.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Designation.append('NA')\n",
    "    \n",
    "# Scraping Company\n",
    "try:\n",
    "    company=driver.find_elements(\"xpath\",'//a[@class=\"ellipsis\"][2]')\n",
    "    for i in company:\n",
    "        Company.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Company.append('NA')\n",
    "# Scraping skill for they hire\n",
    "try:\n",
    "    skill=driver.find_elements(\"xpath\",'//div[@class=\"hireSec highlightable\"]')\n",
    "    for i in skill:\n",
    "        Skill.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Skill.append('NA')\n",
    "    \n",
    "# Scraping Song Artist Name\n",
    "try:\n",
    "    location=driver.find_elements(\"xpath\",'//p[@class=\"highlightable\"]/span[2]/small')\n",
    "    if location:\n",
    "        for i in location:\n",
    "            Location.append(i.text)\n",
    "    else:\n",
    "        Location.append('NA')\n",
    "except NoSuchElementException:\n",
    "    Location.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Name),len(Designation),len(Company),len(Skill),len(Location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3788870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Naukri=pd.DataFrame({})\n",
    "Naukri['Name']=Name[:49]\n",
    "Naukri['Designation']=Designation[:49]\n",
    "Naukri['Company']=Company[:49]\n",
    "Naukri['Skills I Hire for']=Skill[:49]\n",
    "Naukri['Location']=Location[:49]\n",
    "print('\\033[1m'+'Naukri.com Data Science recruiters :'+'\\033[0m')\n",
    "Naukri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5d203",
   "metadata": {},
   "source": [
    "# Q8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fab536",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome('//Users/raj/Desktop/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1ee877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening webpage\n",
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce752912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty Lists\n",
    "Book =[]\n",
    "Author =[]\n",
    "Volumes_sold =[]\n",
    "Publisher =[]\n",
    "Genre =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef25bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Book name\n",
    "try:\n",
    "    book=driver.find_elements(\"xpath\",'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')\n",
    "    for i in book:\n",
    "        Book.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Book.append('NA')\n",
    "    \n",
    "# Scraping Book author's via Xpath\n",
    "try:\n",
    "    author=driver.find_elements(\"xpath\",'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')\n",
    "    for i in author:\n",
    "        Author.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Author.append('NA')\n",
    "    \n",
    "# Scraping Volumes sold via Xpath\n",
    "try:\n",
    "    sold=driver.find_elements(\"xpath\",'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')\n",
    "    for i in sold:\n",
    "        Volumes_sold.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Volumes_sold.append('NA')\n",
    "    \n",
    "# Scraping publisher via xPath\n",
    "try:\n",
    "    publisher=driver.find_elements(\"xpath\",'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')\n",
    "    for i in publisher:\n",
    "        Publisher.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Publisher.append('NA')\n",
    "    \n",
    "# Scraping Genre via Xpath\n",
    "try:\n",
    "    genre=driver.find_elements(\"xpath\",'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6a610",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "Top_Books=pd.DataFrame({\"Book Title\":Book,\n",
    "                \"Author Name\":Author,\n",
    "                'Volumes sold':Volumes_sold,\n",
    "                'Publisher':Publisher,\n",
    "                'Genre':Genre})\n",
    "print('\\033[1m'+'Best Selling Books of All Time List by The Guardian  :'+'\\033[0m')\n",
    "Top_Books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38e16d9",
   "metadata": {},
   "source": [
    "# Q9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17226d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome('//Users/raj/Desktop/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e42e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening webpage\n",
    "url='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb60d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty List\n",
    "Name =[]\n",
    "Year_Span=[]\n",
    "Genre =[]\n",
    "Run_Time =[]\n",
    "Ratings =[]\n",
    "Votes =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2acf9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Name via Xpath\n",
    "try:\n",
    "    name=driver.find_elements(\"xpath\",\"//h3[@class='lister-item-header']/a\")\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append('NA')\n",
    "\n",
    "# Scraping Year span via Xpath\n",
    "try:\n",
    "    year=driver.find_elements(\"xpath\",\"//h3[@class='lister-item-header']/span[2]\")\n",
    "    for i in year:\n",
    "        Year_Span.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year_Span.append('NA')\n",
    "    \n",
    "# Scraping Genre via Xpath\n",
    "try:\n",
    "    genre=driver.find_elements(\"xpath\",\"//span[@class='genre']\")\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Genre.append('NA')\n",
    "    \n",
    "# Scraping RunTime via Xpath\n",
    "try:\n",
    "    runtime=driver.find_elements(\"xpath\",\"//span[@class='runtime']\")\n",
    "    for i in runtime:\n",
    "        Run_Time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Run_Time.append('NA')\n",
    "\n",
    "# Scraping Ratings via Xpath\n",
    "try:\n",
    "    ratings=driver.find_elements(\"xpath\",\"//div[@class='ipl-rating-star small']/span[2]\")\n",
    "    for i in ratings:\n",
    "        Ratings.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Ratings.append('NA')\n",
    "# Scraping Votes via Xpath\n",
    "try:\n",
    "    votes=driver.find_elements(\"xpath\",\"//span[@name='nv']\")\n",
    "    for i in votes:\n",
    "        Votes.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Votes.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d838cda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "IMDB_TV=pd.DataFrame({\"Name\":Name,\n",
    "                \"Year Span\":Year_Span,\n",
    "                \"Genre\":Genre,\n",
    "                \"Run Time\":Run_Time,\n",
    "                \"Ratings\":Ratings,\n",
    "                \"Votes\":Votes})\n",
    "print('\\033[1m'+'Top 100 most watched tv shows of all time IMDB :'+'\\033[0m')\n",
    "IMDB_TV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd9c166",
   "metadata": {},
   "source": [
    "# Q10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c0854",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome('//Users/raj/Desktop/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f5dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening webpage\n",
    "url='https://archive.ics.uci.edu/'\n",
    "driver.get(url)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ce93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on all datasets links\n",
    "dataset=driver.find_element(\"xpath\",\"//a[@href='datasets.php']\")\n",
    "dataset.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ac147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists\n",
    "Dataset =[]\n",
    "Data_Type =[]\n",
    "Task =[]\n",
    "Attribute_Type =[]\n",
    "No_of_Instances =[]\n",
    "No_of_Attribute =[]\n",
    "Year =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20903bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping DataSet Name via Xpath\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    dataset=driver.find_elements(\"xpath\",\"//p[@class='normal']/b/a\")\n",
    "    for i in tqdm(dataset):\n",
    "        Dataset.append(i.text)\n",
    "        time.sleep(0.15)\n",
    "except NoSuchElementException:\n",
    "    Dataset.append('NA')\n",
    "    \n",
    "# Scraping Data Type via Xpath\n",
    "try:\n",
    "    Type=driver.find_elements(\"xpath\",'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[2]')\n",
    "    for i in Type[1:]:\n",
    "        Data_Type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Data_Type.append('NA')\n",
    "    \n",
    "# Scraping Task via Xpath\n",
    "try:\n",
    "    task=driver.find_elements(\"xpath\",'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[3]')\n",
    "    for i in task[1:]:\n",
    "        Task.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Task.append('NA')\n",
    "    \n",
    "# Scraping Attribute_Type via Xpath\n",
    "try:\n",
    "    attribute_Type=driver.find_elements(\"xpath\",'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[4]')\n",
    "    for i in attribute_Type[1:]:\n",
    "        Attribute_Type.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Attribute_Type.append('NA')\n",
    "    \n",
    "# Scraping No_of_Instances via Xpath\n",
    "try:\n",
    "    no_of_Instances=driver.find_elements(\"xpath\",'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[5]')\n",
    "    for i in no_of_Instances[1:]:\n",
    "        No_of_Instances.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Instances.append('NA')\n",
    "# Scraping No_of_Attribute via Xpath\n",
    "try:\n",
    "    no_of_Attribute=driver.find_elements(\"xpath\",'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[6]')\n",
    "    for i in no_of_Attribute[1:]:\n",
    "        No_of_Attribute.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    No_of_Attribute.append('NA')\n",
    "    \n",
    "# Scraping Year via Xpath\n",
    "try:\n",
    "    year=driver.find_elements(\"xpath\",'/html/body/table[2]/tbody/tr/td[2]/table[2]/tbody/tr/td[7]')\n",
    "    for i in year[1:]:\n",
    "        Year.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Year.append('NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de8522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Dataset),len(Data_Type),len(Task),len(Attribute_Type),len(No_of_Instances),len(Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52854a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Data Frame for UCI Dataset\n",
    "UCI_Dataset=pd.DataFrame({'DataSet Title':Dataset,\n",
    "                'Data Type':Data_Type,\n",
    "                'Task':Task,\n",
    "                'Attribute Type':Attribute_Type,\n",
    "                'No of Instances':No_of_Instances,\n",
    "                'No of Attribute':No_of_Attribute})\n",
    "                #'Year':Year })\n",
    "print('\\033[1m'+' UCI Machine Learning Dataset:'+'\\033[0m')\n",
    "UCI_Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
